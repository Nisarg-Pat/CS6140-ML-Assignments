{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0259765",
   "metadata": {
    "id": "c0259765"
   },
   "source": [
    "# CS 6140 Machine Learning: Assignment - 2 (Total Points: 100)\n",
    "## Prof. Ahmad Uzair\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e775045f",
   "metadata": {
    "id": "e775045f"
   },
   "source": [
    "## Question 1 - Naive Bayes Classification (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9372fb",
   "metadata": {
    "id": "ed9372fb"
   },
   "source": [
    "![Q1_1.png](Q1_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a43e9",
   "metadata": {
    "id": "0a5a43e9"
   },
   "source": [
    "![Q1_2.png](Q1_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942651e",
   "metadata": {},
   "source": [
    "## Solution 1:\n",
    "\n",
    "### Step 1: Training the model: \n",
    "\n",
    "Calculating the probabilities $P(y = C_k)$ and $P(x_i=X_{ij}|y=C_k)$ assuming the features are conditionally independent.\n",
    "Here, $y = $ buys\\_computer and $x_i$ is the $i^{th}$ feature.\n",
    "\n",
    "We have:\n",
    "\\begin{equation}\n",
    "P(y = C_k) = \\frac{\\text{count of } y = C_k}{N}\n",
    "\\end{equation}\n",
    "\n",
    "Thus,\n",
    "\\begin{align}\n",
    "P(\\text{y = yes}) &= \\frac{9}{14}\\\\\n",
    "P(\\text{y = yes}) &= \\frac{5}{14}\n",
    "\\end{align}\n",
    "\n",
    "Now,\n",
    "\\begin{equation}\n",
    "P(x_i=X_{ij}|y=C_k) = \\frac{\\text{count of both $x_i=X_{ij}$ and $y=C_k$}}{\\text{count of } y = C_k}\n",
    "\\end{equation}\n",
    "\n",
    "So for age, we have\n",
    "\\begin{align}\n",
    "P(\\text{age=youth}|\\text{y=yes}) &= \\frac{2}{9}\\\\\n",
    "P(\\text{age=youth}|\\text{y=no}) &= \\frac{3}{5}\\\\\n",
    "P(\\text{age=middle_aged}|\\text{y=yes}) &= \\frac{4}{9}\\\\\n",
    "P(\\text{age=middle_aged}|\\text{y=no}) &= \\frac{0}{5}\\\\\n",
    "P(\\text{age=senior}|\\text{y=yes}) &= \\frac{3}{9}\\\\\n",
    "P(\\text{age=senior}|\\text{y=no}) &= \\frac{2}{5}\n",
    "\\end{align}\n",
    "\n",
    "Simmilarly for income, we have\n",
    "\\begin{align}\n",
    "P(\\text{income=low}|\\text{y=yes}) &= \\frac{3}{9}\\\\\n",
    "P(\\text{income=low}|\\text{y=no}) &= \\frac{1}{5}\\\\\n",
    "P(\\text{income=medium}|\\text{y=yes}) &= \\frac{4}{9}\\\\\n",
    "P(\\text{income=medium}|\\text{y=no}) &= \\frac{2}{5}\\\\\n",
    "P(\\text{income=high}|\\text{y=yes}) &= \\frac{2}{9}\\\\\n",
    "P(\\text{income=high}|\\text{y=no}) &= \\frac{2}{5}\n",
    "\\end{align}\n",
    "\n",
    "And for student, we have\n",
    "\\begin{align}\n",
    "P(\\text{student=yes}|\\text{y=yes}) &= \\frac{6}{9}\\\\\n",
    "P(\\text{student=yes}|\\text{y=no}) &= \\frac{1}{5}\\\\\n",
    "P(\\text{student=no}|\\text{y=yes}) &= \\frac{3}{9}\\\\\n",
    "P(\\text{student=no}|\\text{y=no}) &= \\frac{4}{5}\n",
    "\\end{align}\n",
    "\n",
    "And for credit_rating, we have\n",
    "\\begin{align}\n",
    "P(\\text{credit_rating=fair}|\\text{y=yes}) &= \\frac{6}{9}\\\\\n",
    "P(\\text{credit_rating=fair}|\\text{y=no}) &= \\frac{2}{5}\\\\\n",
    "P(\\text{credit_rating=excellent}|\\text{y=yes}) &= \\frac{3}{9}\\\\\n",
    "P(\\text{credit_rating=excellent}|\\text{y=no}) &= \\frac{3}{5}\n",
    "\\end{align}\n",
    "\n",
    "### Step 2: Finding the posteriors:\n",
    "\n",
    "We have:\n",
    "\\begin{align}\n",
    "    P(y = C_k|x_1, x_2, ..., x_m) &\\propto P(y = C_k, x_1, x_2, ..., x_m)\\\\\n",
    "    P(y = C_k, x_1, x_2, ..., x_m) &= P(y = C_k) \\prod_{i=1}^{m} P(x_i|y=C_k)\n",
    "\\end{align}\n",
    "\n",
    "Thus, we have:\n",
    "\n",
    "$P(\\text{y = yes, age = youth, income = medium, student = yes, credit_rating = fair})$\n",
    "$=P(\\text{age=youth}|\\text{y=yes})*P(\\text{income=medium}|\\text{y=yes})*P(\\text{student=yes}|\\text{y=yes})*P(\\text{credit_rating=fair}|\\text{y=yes})*P(\\text{y = yes})$\n",
    "\\begin{align}\n",
    "    &=\\frac{2}{9}*\\frac{4}{9}*\\frac{6}{9}*\\frac{6}{9}*\\frac{9}{14}\\\\\n",
    "    &=0.0282\n",
    "\\end{align}\n",
    "\n",
    "And, we have:\n",
    "$P(\\text{y = no, age = youth, income = medium, student = yes, credit_rating = fair})$\n",
    "$=P(\\text{age=youth}|\\text{y=no})*P(\\text{income=medium}|\\text{y=no})*P(\\text{student=yes}|\\text{y=no})*P(\\text{credit_rating=fair}|\\text{y=no})*P(\\text{y = no})$\n",
    "\\begin{align}\n",
    "    &=\\frac{3}{5}*\\frac{2}{5}*\\frac{1}{5}*\\frac{2}{5}*\\frac{5}{14}\\\\\n",
    "    &=0.0069\n",
    "\\end{align}\n",
    "\n",
    "### Step: 3 Predicting the outcome based on the posteriors:\n",
    "\n",
    "Since $P(\\text{y = yes, age = youth, income = medium, student = yes, credit_rating = fair}) > P(\\text{y = no, age = youth, income = medium, student = yes, credit_rating = fair})$\n",
    "\n",
    "We have $P(\\text{y = yes}| \\text{age = youth, income = medium, student = yes, credit_rating = fair}) > P(\\text{y = no}| \\text{age = youth, income = medium, student = yes, credit_rating = fair})$\n",
    "\n",
    "And hence, $y^* = $ yes.\n",
    "\n",
    "### Thus Naive Bayes predicts that the customer will buy a computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98d11d",
   "metadata": {
    "id": "7c98d11d"
   },
   "source": [
    "## Question 2 - Classification Metrics (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb6759",
   "metadata": {
    "id": "1ffb6759"
   },
   "source": [
    "![Q2.png](Q2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab1581",
   "metadata": {},
   "source": [
    "## Solution 2:\n",
    "\n",
    "### Part 1:\n",
    "\n",
    "\\begin{align}\n",
    "    \\text{False Positives} &= \\text{Number of negative samples incorrectly predicted as positive}\\\\\n",
    "    &=3\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "    \\text{False Negative} &= \\text{Number of positive samples incorrectly predicted as negative}\\\\\n",
    "    &=1\n",
    "\\end{align}\n",
    "\n",
    "### Part 2:\n",
    "\n",
    "We have:\n",
    "\\begin{align}\n",
    "    \\text{Accuracy} &= \\frac{\\text{True Positive}+\\text{True Negative}}{\\text{Total Samples}}\\\\\n",
    "                    &= \\frac{33+72}{33+72+3+1}\\\\\n",
    "                    &= \\frac{105}{109}\\\\\n",
    "                    &=0.9633\n",
    "\\end{align}\n",
    "#### Thus the accuracy of the test is 96.33%.\n",
    "\n",
    "\n",
    "### Part 3:\n",
    "\n",
    "We have:\n",
    "\\begin{align}\n",
    "    \\text{Precision} &= \\frac{\\text{True Positive}}{\\text{True Positive}+\\text{False Positive}}\\\\\n",
    "                    &= \\frac{33}{33+3}\\\\\n",
    "                    &= \\frac{33}{36}\\\\\n",
    "                    &=0.9167\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "    \\text{Recall} &= \\frac{\\text{True Positive}}{\\text{True Positive}+\\text{False Negative}}\\\\\n",
    "                    &= \\frac{33}{33+1}\\\\\n",
    "                    &= \\frac{33}{34}\\\\\n",
    "                    &=0.9706\n",
    "\\end{align}\n",
    "\n",
    "#### Thus the precision of the test is 91.67% and the recall is 97.06%.\n",
    "\n",
    "### Part 4:\n",
    "\n",
    "We have:\n",
    "\\begin{align}\n",
    "    \\text{F1 score} &= \\frac{2}{\\frac{1}{Precision}+\\frac{1}{Recall}}\\\\\n",
    "                    &= \\frac{2}{\\frac{1}{0.9167}+\\frac{1}{0.9706}}\\\\\n",
    "                    &=0.9429\n",
    "\\end{align}\n",
    "\n",
    "#### Thus the F-1 score of the test is 0.9429.\n",
    "\n",
    "### Part 5:\n",
    "\n",
    "According to me, for the covid-19 case, it is more important to predict maximum number of positive cases correctly. There is more at stake when predicting an actual positive case as negative since that person could roam care-free and as the disease is highly contagious, it is more likely that the virus spreads faster. On the other hand if an actual negative person is predicted as positive than the worst that would happen is that he would have to stay at home for some time till a test correctly predicts him as negative. As minimizing false negative is more important in Covid-19 to reduce the spread than minimizing false positives, out of the two models, **I would prefer the one that has higher recall than the one that has higher precision.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca0ce4f",
   "metadata": {
    "id": "0ca0ce4f"
   },
   "source": [
    "## Question 3 -  Logistic Regression and Perceptron  (70 points)\n",
    "\n",
    " In this problem you will be applying logistic regression and perceptron to the breastcancer dataset for binary classification:\n",
    "\n",
    " **default of credit card clients**:  This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbee24d",
   "metadata": {
    "id": "fdbee24d"
   },
   "source": [
    "### Task\n",
    "- Prepare a normalized version of data. Use min-max normalization. \n",
    "- Train two logistic regression models using gradient descent with raw as well as normalized data. \n",
    "- Train two perceptron classifiers with raw as well as normalized data.\n",
    "- Compare training and test results of four models in terms of accuracy. \n",
    "\n",
    "Note:\n",
    "\n",
    "The skeleton code is only a guide. You can change the method definitions where necessary with appropriate comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7d425c",
   "metadata": {
    "id": "4b7d425c"
   },
   "outputs": [],
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67fca1",
   "metadata": {
    "id": "6f67fca1"
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    ''' data: input features\n",
    "        labels: output features\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2391d",
   "metadata": {
    "id": "2bb2391d"
   },
   "source": [
    "### 1) Implementation of sigmoid and cost function (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f982e9",
   "metadata": {
    "id": "10f982e9"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' return sigmoid'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0962e",
   "metadata": {
    "id": "f0b0962e"
   },
   "outputs": [],
   "source": [
    "## Implement the loss function for logistic regression\n",
    "\n",
    "def compute_cost(ip, op, params):\n",
    "    \"\"\"\n",
    "    Cost function in linear regression where the cost is calculated\n",
    "    ip: input variables\n",
    "    op: output variables\n",
    "    params: corresponding parameters\n",
    "    Returns cost\n",
    "    \"\"\"\n",
    "#     print (cost_sum)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced13867",
   "metadata": {
    "id": "ced13867"
   },
   "source": [
    "\n",
    "### 2)  Implement logistic regression using batch gradient descent and evaluation (20 points)\n",
    "Algorithm can be given as follows:\n",
    "\n",
    "```for j in 0 -> max_iteration: \n",
    "    for i in 0 -> m: \n",
    "        theta += (alpha / m) * (y[i] - h(x[i])) * x_bar\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb063fa6",
   "metadata": {
    "id": "cb063fa6"
   },
   "outputs": [],
   "source": [
    "def logistic_regression_using_batch_gradient_descent(ip, op, params, alpha, max_iter, batch_size = 1):\n",
    "    \"\"\"\n",
    "    Compute the params for logistic regression using batch gradient descent\n",
    "    ip: input variables\n",
    "    op: output variables\n",
    "    params: corresponding parameters\n",
    "    alpha: learning rate\n",
    "    max_iter: maximum number of iterations\n",
    "    Returns parameters, cost, params_store\n",
    "    \"\"\" \n",
    "    # initialize iteration, number of samples, cost and parameter array\n",
    "\n",
    "    \n",
    "    #batchify the data into mini-batches\n",
    "\n",
    "    \n",
    "    \n",
    "    # Compute the cost and store the params for the corresponding cost\n",
    "\n",
    "    \n",
    "    return params, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e26ce",
   "metadata": {
    "id": "3f5e26ce"
   },
   "source": [
    "### 3) Implementation of perceptron.(20 points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68380bd3",
   "metadata": {
    "id": "68380bd3"
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "# constructor \n",
    "    def __init__ (self):\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "# model\n",
    "\n",
    "    \n",
    "# fitting the model    \n",
    "    \n",
    "    \n",
    "    \n",
    "# predictor to predict on the data based on w "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84b7b4",
   "metadata": {
    "id": "1f84b7b4"
   },
   "source": [
    "### 4) Apply 80-20 split on data to prepare training and test sets. Report training and test results in terms of accuracy, precision and recall for both logistic regression and perceptron. (20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0d71e",
   "metadata": {
    "id": "cae0d71e"
   },
   "outputs": [],
   "source": [
    "# Sample training code cell change according to your variables and structure\n",
    "\n",
    "# Training the model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#reserve the test data, do not use them for cross-validation!\n",
    "\n",
    "data, labels = load_data(DATA_DIR)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.20)\n",
    "x_train = np.append(x_train, np.ones((x_train.shape[0],1)), axis=1)\n",
    "x_test = np.append(x_test, np.ones((x_test.shape[0],1)), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582ec4f",
   "metadata": {
    "id": "8582ec4f"
   },
   "outputs": [],
   "source": [
    "def evaluate(x_test, y_test,params):\n",
    "    '''return the accuracy scores'''\n",
    "\n",
    "    return acc\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa2d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CS6140-Assign_2_Summer22.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}